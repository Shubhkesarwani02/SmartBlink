{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1245fc3d",
   "metadata": {},
   "source": [
    "# üó∫Ô∏è Phase 2: Map Data & Processing Pipeline\n",
    "\n",
    "This notebook implements the complete geospatial data processing pipeline for SmartBlink:\n",
    "\n",
    "## Objectives:\n",
    "1. **Data Ingestion**: Load synthetic orders from PostgreSQL\n",
    "2. **GeoDataFrame Conversion**: Convert to GeoDataFrame with EPSG:4326\n",
    "3. **H3 Grid Aggregation**: Use hexagonal indexing (resolution 8)\n",
    "4. **Demand Analysis**: Calculate order counts, values, and temporal patterns\n",
    "5. **Distance Calculation**: Precompute distances to nearest stores using OSRM\n",
    "6. **Storage**: Update demand_cells table in PostGIS\n",
    "7. **Visualization**: Generate hex grid and demand heatmaps\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: SmartBlink Team  \n",
    "**Date**: November 2025  \n",
    "**Phase**: 2 - Data Processing Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000fc1c",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Required Libraries\n",
    "\n",
    "Install and import all necessary geospatial, data processing, and visualization libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d40c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Geospatial libraries\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point, Polygon\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wkt\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m options\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeoseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeoSeries\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeodataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeoDataFrame\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/_config.py:109\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcompat\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     compat\u001b[38;5;241m.\u001b[39mset_use_pygeos(value)\n\u001b[1;32m    107\u001b[0m use_pygeos \u001b[38;5;241m=\u001b[39m Option(\n\u001b[1;32m    108\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_pygeos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 109\u001b[0m     default_value\u001b[38;5;241m=\u001b[39m\u001b[43m_default_use_pygeos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    110\u001b[0m     doc\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhether to use PyGEOS to speed up spatial operations. The default is True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif PyGEOS is installed, and follows the USE_PYGEOS environment variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     ),\n\u001b[1;32m    115\u001b[0m     validator\u001b[38;5;241m=\u001b[39m_validate_bool,\n\u001b[1;32m    116\u001b[0m     callback\u001b[38;5;241m=\u001b[39m_callback_use_pygeos,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_io_engine\u001b[39m(value):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/_config.py:95\u001b[0m, in \u001b[0;36m_default_use_pygeos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_default_use_pygeos\u001b[39m():\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcompat\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mUSE_PYGEOS\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/_compat.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeos\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# pandas compat\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/shapely/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m geos_capi_version, geos_capi_version_string  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_signal_checks  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_geometry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstructive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/shapely/_geometry.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _geometry_helpers, geos_version, lib\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParamEnum\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multithreading_enabled, requires_geos\n",
      "File \u001b[0;32mshapely/_geometry_helpers.pyx:1\u001b[0m, in \u001b[0;36minit shapely._geometry_helpers\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely import wkt\n",
    "import h3\n",
    "\n",
    "# Database\n",
    "from prisma import Prisma\n",
    "import asyncio\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# HTTP requests for OSRM\n",
    "import requests\n",
    "import aiohttp\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"üì¶ H3 version: {h3.__version__}\")\n",
    "print(f\"üì¶ Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cfa0e",
   "metadata": {},
   "source": [
    "## 2. Configuration & Database Connection\n",
    "\n",
    "Set up database connection string and OSRM endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Database: localhost:5432/smartblink\n",
      "üó∫Ô∏è  H3 Resolution: 8\n",
      "üîß OSRM Enabled: False\n",
      "üìÖ Analysis Period: 90 days\n"
     ]
    }
   ],
   "source": [
    "# Database configuration\n",
    "DATABASE_URL = \"postgresql://smartblink:smartblink123@postgres:5432/smartblink\"\n",
    "\n",
    "# If running outside Docker, use localhost\n",
    "if not os.path.exists('/.dockerenv'):\n",
    "    DATABASE_URL = \"postgresql://smartblink:smartblink123@localhost:5432/smartblink\"\n",
    "\n",
    "# OSRM endpoint (optional - uncomment when OSRM is running)\n",
    "OSRM_URL = \"http://localhost:5000\"\n",
    "USE_OSRM = False  # Set to True when OSRM is available\n",
    "\n",
    "# H3 configuration\n",
    "H3_RESOLUTION = 8  # ~0.7km¬≤ hexagons\n",
    "\n",
    "# Analysis parameters\n",
    "ANALYSIS_DAYS = 90  # Look back 90 days\n",
    "\n",
    "print(f\"üìä Database: {DATABASE_URL.split('@')[-1]}\")\n",
    "print(f\"üó∫Ô∏è  H3 Resolution: {H3_RESOLUTION}\")\n",
    "print(f\"üîß OSRM Enabled: {USE_OSRM}\")\n",
    "print(f\"üìÖ Analysis Period: {ANALYSIS_DAYS} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce96241",
   "metadata": {},
   "source": [
    "## 3. Load Synthetic Orders from PostgreSQL\n",
    "\n",
    "Load order data from the database and inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e3cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Connect and load orders\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m(DATABASE_URL)\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mSELECT \u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    id,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mORDER BY timestamp DESC;\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müì• Loading orders from database...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# Connect and load orders\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    ST_Y(location) as latitude,\n",
    "    ST_X(location) as longitude,\n",
    "    timestamp,\n",
    "    items_count,\n",
    "    order_value,\n",
    "    customer_id,\n",
    "    delivery_time_min,\n",
    "    status\n",
    "FROM orders\n",
    "ORDER BY timestamp DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üì• Loading orders from database...\")\n",
    "df_orders = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df_orders):,} orders\")\n",
    "print(f\"\\nüìä Data Shape: {df_orders.shape}\")\n",
    "print(f\"üìÖ Date Range: {df_orders['timestamp'].min()} to {df_orders['timestamp'].max()}\")\n",
    "print(f\"üí∞ Total Value: ‚Çπ{df_orders['order_value'].sum():,.2f}\")\n",
    "print(f\"\\nüîç Sample Data:\")\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e56b26",
   "metadata": {},
   "source": [
    "## 4. Convert to GeoDataFrame with EPSG:4326\n",
    "\n",
    "Transform pandas DataFrame into a GeoDataFrame with proper geometric projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd534c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_orders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create Point geometries from lat/lon\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m geometry \u001b[38;5;241m=\u001b[39m [Point(xy) \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mdf_orders\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m], df_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create GeoDataFrame\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gdf_orders \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\n\u001b[1;32m      6\u001b[0m     df_orders,\n\u001b[1;32m      7\u001b[0m     geometry\u001b[38;5;241m=\u001b[39mgeometry,\n\u001b[1;32m      8\u001b[0m     crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# WGS84 - standard GPS coordinates\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_orders' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Point geometries from lat/lon\n",
    "geometry = [Point(xy) for xy in zip(df_orders['longitude'], df_orders['latitude'])]\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_orders = gpd.GeoDataFrame(\n",
    "    df_orders,\n",
    "    geometry=geometry,\n",
    "    crs=\"EPSG:4326\"  # WGS84 - standard GPS coordinates\n",
    ")\n",
    "\n",
    "# Verify CRS\n",
    "print(f\"‚úÖ GeoDataFrame created\")\n",
    "print(f\"üìç CRS: {gdf_orders.crs}\")\n",
    "print(f\"üó∫Ô∏è  Geometry Type: {gdf_orders.geometry.geom_type.unique()[0]}\")\n",
    "print(f\"üìè Bounds: {gdf_orders.total_bounds}\")\n",
    "\n",
    "# Display sample\n",
    "gdf_orders[['latitude', 'longitude', 'order_value', 'timestamp', 'geometry']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bd580",
   "metadata": {},
   "source": [
    "## 5. H3 Hexagonal Grid Aggregation\n",
    "\n",
    "Apply H3 hexagonal indexing to create spatial bins for demand aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∑ Applying H3 indexing at resolution 8...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gdf_orders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m gdf_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgdf_orders\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: lat_lon_to_h3(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     14\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Remove any null H3 indices\u001b[39;00m\n\u001b[1;32m     18\u001b[0m gdf_orders \u001b[38;5;241m=\u001b[39m gdf_orders[gdf_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdf_orders' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply H3 indexing to each order\n",
    "print(f\"üî∑ Applying H3 indexing at resolution {H3_RESOLUTION}...\")\n",
    "\n",
    "def lat_lon_to_h3(lat, lon, resolution=H3_RESOLUTION):\n",
    "    \"\"\"Convert lat/lon to H3 hexagon ID\"\"\"\n",
    "    try:\n",
    "        # H3 v4 API: h3.latlng_to_cell()\n",
    "        return h3.latlng_to_cell(lat, lon, resolution)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "gdf_orders['h3_index'] = gdf_orders.apply(\n",
    "    lambda row: lat_lon_to_h3(row['latitude'], row['longitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Remove any null H3 indices\n",
    "gdf_orders = gdf_orders[gdf_orders['h3_index'].notna()]\n",
    "\n",
    "# Get unique hexagons\n",
    "unique_hexes = gdf_orders['h3_index'].nunique()\n",
    "print(f\"‚úÖ Assigned {len(gdf_orders):,} orders to {unique_hexes:,} unique hexagons\")\n",
    "print(f\"üìä Average orders per hex: {len(gdf_orders) / unique_hexes:.1f}\")\n",
    "\n",
    "# Sample\n",
    "gdf_orders[['latitude', 'longitude', 'h3_index', 'order_value']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32470a",
   "metadata": {},
   "source": [
    "## 6. Aggregate Demand Metrics by Hexagon\n",
    "\n",
    "Calculate key metrics for each hexagon: order count, average value, and temporal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5adac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_orders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract hour from timestamp for temporal analysis\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gdf_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgdf_orders\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Aggregate by H3 hexagon\u001b[39;00m\n\u001b[1;32m      5\u001b[0m demand_aggregation \u001b[38;5;241m=\u001b[39m gdf_orders\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3_index\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# order_count\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_value\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# value metrics\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdf_orders' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract hour from timestamp for temporal analysis\n",
    "gdf_orders['hour'] = gdf_orders['timestamp'].dt.hour\n",
    "\n",
    "# Aggregate by H3 hexagon\n",
    "demand_aggregation = gdf_orders.groupby('h3_index').agg({\n",
    "    'id': 'count',  # order_count\n",
    "    'order_value': ['sum', 'mean', 'std'],  # value metrics\n",
    "    'hour': lambda x: x.mode()[0] if len(x) > 0 else 12,  # peak_hour\n",
    "    'delivery_time_min': 'mean',  # avg delivery time\n",
    "    'latitude': 'first',  # for getting centroid (we'll recalculate properly)\n",
    "    'longitude': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "demand_aggregation.columns = [\n",
    "    'h3_index', 'orders_count', 'total_order_value', \n",
    "    'avg_order_value', 'std_order_value', 'peak_hour',\n",
    "    'avg_delivery_time', 'sample_lat', 'sample_lon'\n",
    "]\n",
    "\n",
    "# Calculate demand score (normalized 0-10)\n",
    "max_orders = demand_aggregation['orders_count'].max()\n",
    "demand_aggregation['demand_score'] = (\n",
    "    demand_aggregation['orders_count'] / max_orders * 10\n",
    ").round(2)\n",
    "\n",
    "print(f\"‚úÖ Aggregated {len(demand_aggregation):,} demand cells\")\n",
    "print(f\"\\nüìä Demand Statistics:\")\n",
    "print(demand_aggregation[['orders_count', 'avg_order_value', 'demand_score']].describe())\n",
    "\n",
    "demand_aggregation.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3dc2b",
   "metadata": {},
   "source": [
    "## 7. Calculate H3 Hexagon Centroids & Geometries\n",
    "\n",
    "Get the true geographic centroid for each hexagon and create polygon geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1979189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∑ Computing hexagon centroids and geometries...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'demand_aggregation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müî∑ Computing hexagon centroids and geometries...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate centroids\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m demand_aggregation[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentroid_lat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentroid_lon\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdemand_aggregation\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(h3_to_centroid(x))\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create polygon geometries\u001b[39;00m\n\u001b[1;32m     24\u001b[0m demand_aggregation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m demand_aggregation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(h3_to_polygon)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'demand_aggregation' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to get H3 hexagon boundaries\n",
    "def h3_to_polygon(h3_index):\n",
    "    \"\"\"Convert H3 index to Shapely Polygon\"\"\"\n",
    "    # H3 v4 API: h3.cell_to_boundary()\n",
    "    boundary = h3.cell_to_boundary(h3_index, geo_json=True)\n",
    "    # H3 returns [lon, lat], but Shapely expects (lon, lat)\n",
    "    return Polygon(boundary)\n",
    "\n",
    "# Function to get H3 centroid\n",
    "def h3_to_centroid(h3_index):\n",
    "    \"\"\"Get centroid lat/lon from H3 index\"\"\"\n",
    "    # H3 v4 API: h3.cell_to_latlng()\n",
    "    lat, lon = h3.cell_to_latlng(h3_index)\n",
    "    return lat, lon\n",
    "\n",
    "print(\"üî∑ Computing hexagon centroids and geometries...\")\n",
    "\n",
    "# Calculate centroids\n",
    "demand_aggregation[['centroid_lat', 'centroid_lon']] = demand_aggregation['h3_index'].apply(\n",
    "    lambda x: pd.Series(h3_to_centroid(x))\n",
    ")\n",
    "\n",
    "# Create polygon geometries\n",
    "demand_aggregation['geometry'] = demand_aggregation['h3_index'].apply(h3_to_polygon)\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_demand = gpd.GeoDataFrame(\n",
    "    demand_aggregation,\n",
    "    geometry='geometry',\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created {len(gdf_demand):,} hexagon polygons\")\n",
    "print(f\"üìç Centroid example: ({gdf_demand.iloc[0]['centroid_lat']:.4f}, {gdf_demand.iloc[0]['centroid_lon']:.4f})\")\n",
    "\n",
    "gdf_demand[['h3_index', 'orders_count', 'demand_score', 'centroid_lat', 'centroid_lon']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f89073",
   "metadata": {},
   "source": [
    "## 8. Calculate Distance to Nearest Store\n",
    "\n",
    "For each hexagon, we'll calculate:\n",
    "- **Road network distance** using OSRM (if available)\n",
    "- **Fallback to Euclidean distance** if OSRM is unavailable\n",
    "- **Travel time** to nearest store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Loading stores from database...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìç Loading stores from database...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m stores_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m        id,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m    ORDER BY id;\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m stores_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(stores_query, \u001b[43mengine\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(stores_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m stores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(stores_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# Load stores from database\n",
    "print(\"üìç Loading stores from database...\")\n",
    "stores_query = \"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        name,\n",
    "        ST_Y(location::geometry) as lat,\n",
    "        ST_X(location::geometry) as lon\n",
    "    FROM stores\n",
    "    ORDER BY id;\n",
    "\"\"\"\n",
    "\n",
    "stores_df = pd.read_sql(stores_query, engine)\n",
    "print(f\"‚úÖ Loaded {len(stores_df)} stores\")\n",
    "print(stores_df[['id', 'name', 'lat', 'lon']])\n",
    "\n",
    "# Function to calculate Euclidean distance as fallback\n",
    "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance in meters using Haversine formula\"\"\"\n",
    "    from math import radians, sin, cos, sqrt, atan2\n",
    "    \n",
    "    R = 6371000  # Earth radius in meters\n",
    "    \n",
    "    lat1_rad, lon1_rad = radians(lat1), radians(lon1)\n",
    "    lat2_rad, lon2_rad = radians(lat2), radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "# Function to query OSRM for distances\n",
    "async def get_osrm_distances_batch(centroids: List[Tuple[float, float]], \n",
    "                                     stores: List[Tuple[float, float]]) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Query OSRM table service to get distance matrix\n",
    "    Returns: distances array [centroids x stores] in meters, or None if OSRM unavailable\n",
    "    \"\"\"\n",
    "    if not USE_OSRM:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Format coordinates as lon,lat for OSRM\n",
    "        centroid_coords = \";\".join([f\"{lon},{lat}\" for lat, lon in centroids])\n",
    "        store_coords = \";\".join([f\"{lon},{lat}\" for lat, lon in stores])\n",
    "        all_coords = f\"{centroid_coords};{store_coords}\"\n",
    "        \n",
    "        # OSRM table service\n",
    "        url = f\"{OSRM_URL}/table/v1/driving/{all_coords}\"\n",
    "        params = {\n",
    "            \"sources\": \";\".join([str(i) for i in range(len(centroids))]),\n",
    "            \"destinations\": \";\".join([str(i) for i in range(len(centroids), len(centroids) + len(stores))])\n",
    "        }\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params, timeout=30) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    distances = np.array(data['distances'])\n",
    "                    return distances\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è OSRM returned status {response.status}\")\n",
    "                    return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è OSRM not available: {e}\")\n",
    "        return None\n",
    "\n",
    "# Calculate distances\n",
    "print(\"\\nüöó Calculating distances to nearest store...\")\n",
    "\n",
    "# Prepare store coordinates\n",
    "store_coords = list(zip(stores_df['lat'], stores_df['lon']))\n",
    "\n",
    "# Initialize distance columns\n",
    "gdf_demand['dist_nearest_store_m'] = 0.0\n",
    "gdf_demand['travel_time_nearest_store_sec'] = 0.0\n",
    "gdf_demand['nearest_store_id'] = None\n",
    "\n",
    "# Try OSRM first (batch processing)\n",
    "if USE_OSRM:\n",
    "    print(\"Attempting OSRM distance calculation...\")\n",
    "    centroid_coords = list(zip(gdf_demand['centroid_lat'], gdf_demand['centroid_lon']))\n",
    "    \n",
    "    # Process in batches of 100 to avoid timeout\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(centroid_coords), batch_size):\n",
    "        batch = centroid_coords[i:i+batch_size]\n",
    "        distances = asyncio.run(get_osrm_distances_batch(batch, store_coords))\n",
    "        \n",
    "        if distances is not None:\n",
    "            # Find minimum distance and corresponding store for each hexagon\n",
    "            min_indices = np.argmin(distances, axis=1)\n",
    "            min_distances = distances[np.arange(len(batch)), min_indices]\n",
    "            \n",
    "            gdf_demand.loc[i:i+len(batch)-1, 'dist_nearest_store_m'] = min_distances\n",
    "            gdf_demand.loc[i:i+len(batch)-1, 'nearest_store_id'] = stores_df.iloc[min_indices]['id'].values\n",
    "            \n",
    "            # Estimate travel time (assuming 25 km/h average speed in city)\n",
    "            gdf_demand.loc[i:i+len(batch)-1, 'travel_time_nearest_store_sec'] = min_distances / (25000/3600)\n",
    "        else:\n",
    "            USE_OSRM = False\n",
    "            break\n",
    "        \n",
    "        if (i + batch_size) % 500 == 0:\n",
    "            print(f\"  Processed {min(i + batch_size, len(centroid_coords)):,}/{len(centroid_coords):,} hexagons\")\n",
    "\n",
    "# Fallback to Euclidean distance\n",
    "if not USE_OSRM or gdf_demand['dist_nearest_store_m'].sum() == 0:\n",
    "    print(\"üìê Using Euclidean distance (OSRM not available)...\")\n",
    "    \n",
    "    for idx, row in gdf_demand.iterrows():\n",
    "        hex_lat, hex_lon = row['centroid_lat'], row['centroid_lon']\n",
    "        \n",
    "        # Calculate distance to each store\n",
    "        distances = [\n",
    "            euclidean_distance(hex_lat, hex_lon, store_lat, store_lon)\n",
    "            for store_lat, store_lon in store_coords\n",
    "        ]\n",
    "        \n",
    "        # Find nearest store\n",
    "        min_idx = np.argmin(distances)\n",
    "        min_dist = distances[min_idx]\n",
    "        \n",
    "        gdf_demand.at[idx, 'dist_nearest_store_m'] = min_dist\n",
    "        gdf_demand.at[idx, 'nearest_store_id'] = stores_df.iloc[min_idx]['id']\n",
    "        \n",
    "        # Estimate travel time (assuming 25 km/h + 20% detour factor for road network)\n",
    "        gdf_demand.at[idx, 'travel_time_nearest_store_sec'] = (min_dist * 1.2) / (25000/3600)\n",
    "\n",
    "print(\"\\n‚úÖ Distance calculation complete!\")\n",
    "print(f\"üìä Distance stats:\")\n",
    "print(f\"  - Min: {gdf_demand['dist_nearest_store_m'].min():.0f}m\")\n",
    "print(f\"  - Max: {gdf_demand['dist_nearest_store_m'].max():.0f}m\")\n",
    "print(f\"  - Mean: {gdf_demand['dist_nearest_store_m'].mean():.0f}m\")\n",
    "print(f\"  - Median: {gdf_demand['dist_nearest_store_m'].median():.0f}m\")\n",
    "\n",
    "gdf_demand[['h3_index', 'orders_count', 'demand_score', 'dist_nearest_store_m', 'travel_time_nearest_store_sec']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202a940",
   "metadata": {},
   "source": [
    "## 9. Store Results in PostGIS Database\n",
    "\n",
    "Update the `demand_cells` table with calculated metrics and geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "print(\"üíæ Storing demand cell data in PostGIS...\")\n",
    "\n",
    "# Drop existing demand cells to replace with H3-based cells\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text('DELETE FROM demand_cells'))\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Cleared existing demand cells\")\n",
    "\n",
    "# Prepare data for insertion\n",
    "insert_count = 0\n",
    "errors = []\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    for idx, row in gdf_demand.iterrows():\n",
    "        try:\n",
    "            # Convert polygon to WKT\n",
    "            polygon_wkt = row['geometry'].wkt\n",
    "            \n",
    "            # Use proper date range from orders\n",
    "            period_start = gdf_orders['timestamp'].min()\n",
    "            period_end = gdf_orders['timestamp'].max()\n",
    "            \n",
    "            insert_query = text(\"\"\"\n",
    "                INSERT INTO demand_cells (\n",
    "                    h3_index,\n",
    "                    cell_geometry,\n",
    "                    orders_count,\n",
    "                    total_order_value,\n",
    "                    avg_order_value,\n",
    "                    demand_score,\n",
    "                    distance_to_nearest_store,\n",
    "                    peak_hour,\n",
    "                    period_start,\n",
    "                    period_end\n",
    "                ) VALUES (\n",
    "                    :h3_index,\n",
    "                    ST_SetSRID(ST_GeomFromText(:geometry), 4326),\n",
    "                    :order_count,\n",
    "                    :total_demand,\n",
    "                    :avg_order_value,\n",
    "                    :demand_score,\n",
    "                    :distance,\n",
    "                    :peak_hour,\n",
    "                    :period_start,\n",
    "                    :period_end\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(insert_query, {\n",
    "                'h3_index': row['h3_index'],\n",
    "                'geometry': polygon_wkt,\n",
    "                'order_count': int(row['orders_count']),\n",
    "                'total_demand': float(row['total_order_value']),\n",
    "                'avg_order_value': float(row['avg_order_value']),\n",
    "                'demand_score': float(row['demand_score']),\n",
    "                'distance': float(row['dist_nearest_store_m']),\n",
    "                'peak_hour': int(row['peak_hour']) if row['peak_hour'] is not None else 12,\n",
    "                'period_start': period_start,\n",
    "                'period_end': period_end\n",
    "            })\n",
    "            \n",
    "            insert_count += 1\n",
    "            \n",
    "            if insert_count % 100 == 0:\n",
    "                conn.commit()\n",
    "                print(f\"  Inserted {insert_count}/{len(gdf_demand)} cells...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors.append(f\"Row {idx}: {str(e)}\")\n",
    "            if len(errors) <= 5:\n",
    "                print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully inserted {insert_count} demand cells into PostGIS\")\n",
    "if errors:\n",
    "    print(f\"‚ö†Ô∏è {len(errors)} errors occurred\")\n",
    "\n",
    "# Verify insertion\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text('SELECT COUNT(*) as count FROM demand_cells'))\n",
    "    count = result.fetchone()[0]\n",
    "    print(f\"\\nüìä Database verification: {count} demand cells in PostGIS\")\n",
    "    \n",
    "    # Sample query with spatial data\n",
    "    sample = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            h3_index,\n",
    "            orders_count,\n",
    "            demand_score,\n",
    "            ROUND(distance_to_nearest_store::numeric, 0) as dist_m,\n",
    "            ST_AsText(ST_Centroid(cell_geometry)) as centroid\n",
    "        FROM demand_cells\n",
    "        ORDER BY demand_score DESC\n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(\"\\nüî• Top 5 demand cells:\")\n",
    "    for row in sample:\n",
    "        print(f\"  H3: {row[0][:10]}... | Orders: {row[1]:3d} | Score: {row[2]:.1f} | Dist: {row[3]}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e40956",
   "metadata": {},
   "source": [
    "## 10. Visualizations\n",
    "\n",
    "Create comprehensive visualizations to analyze demand patterns and validate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "\n",
    "print(\"üìä Creating visualizations...\")\n",
    "\n",
    "# 1. Demand Heatmap (Matplotlib)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# A. Hexagon Grid with Demand Score\n",
    "ax1 = axes[0, 0]\n",
    "gdf_demand.plot(\n",
    "    column='demand_score',\n",
    "    cmap='YlOrRd',\n",
    "    legend=True,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.7,\n",
    "    ax=ax1\n",
    ")\n",
    "# Plot stores\n",
    "stores_gdf = gpd.GeoDataFrame(\n",
    "    stores_df,\n",
    "    geometry=gpd.points_from_xy(stores_df['lon'], stores_df['lat']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "stores_gdf.plot(ax=ax1, color='blue', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax1.set_title('H3 Hexagon Grid - Demand Score Heatmap', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.legend()\n",
    "\n",
    "# B. Order Count Heatmap\n",
    "ax2 = axes[0, 1]\n",
    "gdf_demand.plot(\n",
    "    column='orders_count',\n",
    "    cmap='plasma',\n",
    "    legend=True,\n",
    "    edgecolor='gray',\n",
    "    linewidth=0.2,\n",
    "    alpha=0.8,\n",
    "    ax=ax2\n",
    ")\n",
    "stores_gdf.plot(ax=ax2, color='cyan', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax2.set_title('Order Count per Hexagon', fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel('Longitude')\n",
    "ax2.set_ylabel('Latitude')\n",
    "ax2.legend()\n",
    "\n",
    "# C. Average Order Value\n",
    "ax3 = axes[1, 0]\n",
    "gdf_demand.plot(\n",
    "    column='avg_order_value',\n",
    "    cmap='viridis',\n",
    "    legend=True,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.7,\n",
    "    ax=ax3\n",
    ")\n",
    "stores_gdf.plot(ax=ax3, color='red', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax3.set_title('Average Order Value (‚Çπ)', fontsize=16, fontweight='bold')\n",
    "ax3.set_xlabel('Longitude')\n",
    "ax3.set_ylabel('Latitude')\n",
    "ax3.legend()\n",
    "\n",
    "# D. Distance to Nearest Store\n",
    "ax4 = axes[1, 1]\n",
    "gdf_demand.plot(\n",
    "    column='dist_nearest_store_m',\n",
    "    cmap='coolwarm_r',\n",
    "    legend=True,\n",
    "    edgecolor='gray',\n",
    "    linewidth=0.2,\n",
    "    alpha=0.8,\n",
    "    ax=ax4\n",
    ")\n",
    "stores_gdf.plot(ax=ax4, color='green', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax4.set_title('Distance to Nearest Store (meters)', fontsize=16, fontweight='bold')\n",
    "ax4.set_xlabel('Longitude')\n",
    "ax4.set_ylabel('Latitude')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/phase2_demand_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: outputs/phase2_demand_analysis.png\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Statistical Distribution Plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Distribution of demand scores\n",
    "axes[0, 0].hist(gdf_demand['demand_score'], bins=30, color='orange', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Demand Scores', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Demand Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(gdf_demand['demand_score'].mean(), color='red', linestyle='--', label=f'Mean: {gdf_demand[\"demand_score\"].mean():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Distribution of order counts\n",
    "axes[0, 1].hist(gdf_demand['orders_count'], bins=30, color='purple', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of Order Counts', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Orders per Hexagon')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(gdf_demand['orders_count'].mean(), color='red', linestyle='--', label=f'Mean: {gdf_demand[\"orders_count\"].mean():.1f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Distribution of distances\n",
    "axes[1, 0].hist(gdf_demand['dist_nearest_store_m'], bins=30, color='teal', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('Distribution of Distances to Nearest Store', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Distance (meters)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(gdf_demand['dist_nearest_store_m'].mean(), color='red', linestyle='--', label=f'Mean: {gdf_demand[\"dist_nearest_store_m\"].mean():.0f}m')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Scatter: Demand Score vs Distance\n",
    "axes[1, 1].scatter(gdf_demand['dist_nearest_store_m'], gdf_demand['demand_score'], \n",
    "                   alpha=0.6, c=gdf_demand['orders_count'], cmap='viridis', s=50)\n",
    "axes[1, 1].set_title('Demand Score vs Distance to Store', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Distance to Nearest Store (m)')\n",
    "axes[1, 1].set_ylabel('Demand Score')\n",
    "cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "cbar.set_label('Order Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/phase2_statistical_distributions.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: outputs/phase2_statistical_distributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Interactive Folium Map\n",
    "import folium\n",
    "from folium import plugins\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "print(\"üó∫Ô∏è Creating interactive Folium map...\")\n",
    "\n",
    "# Create base map centered on Delhi NCR\n",
    "center_lat = gdf_demand['centroid_lat'].mean()\n",
    "center_lon = gdf_demand['centroid_lon'].mean()\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=11,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Create colormap for demand score\n",
    "colormap = LinearColormap(\n",
    "    colors=['yellow', 'orange', 'red', 'darkred'],\n",
    "    vmin=gdf_demand['demand_score'].min(),\n",
    "    vmax=gdf_demand['demand_score'].max(),\n",
    "    caption='Demand Score'\n",
    ")\n",
    "\n",
    "# Add hexagon polygons\n",
    "for idx, row in gdf_demand.iterrows():\n",
    "    # Get polygon coordinates\n",
    "    coords = list(row['geometry'].exterior.coords)\n",
    "    coords_folium = [[lat, lon] for lon, lat in coords]\n",
    "    \n",
    "    # Color based on demand score\n",
    "    color = colormap(row['demand_score'])\n",
    "    \n",
    "    # Create popup\n",
    "    popup_html = f\"\"\"\n",
    "    <b>H3 Index:</b> {row['h3_index']}<br>\n",
    "    <b>Orders:</b> {row['orders_count']}<br>\n",
    "    <b>Demand Score:</b> {row['demand_score']:.2f}<br>\n",
    "    <b>Avg Order Value:</b> ‚Çπ{row['avg_order_value']:.0f}<br>\n",
    "    <b>Distance to Store:</b> {row['dist_nearest_store_m']:.0f}m<br>\n",
    "    <b>Peak Hour:</b> {row['peak_hour']:.0f}:00\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.Polygon(\n",
    "        locations=coords_folium,\n",
    "        color='black',\n",
    "        weight=1,\n",
    "        fill=True,\n",
    "        fillColor=color,\n",
    "        fillOpacity=0.6,\n",
    "        popup=folium.Popup(popup_html, max_width=300)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add store markers\n",
    "for idx, store in stores_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[store['lat'], store['lon']],\n",
    "        popup=f\"<b>{store['name']}</b><br>Store ID: {store['id']}\",\n",
    "        icon=folium.Icon(color='blue', icon='shopping-cart', prefix='fa'),\n",
    "        tooltip=store['name']\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add colormap legend\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save map\n",
    "m.save('../outputs/phase2_interactive_map.html')\n",
    "print(\"‚úÖ Saved: outputs/phase2_interactive_map.html\")\n",
    "print(\"   Open this file in a browser to explore the interactive map!\")\n",
    "\n",
    "# Display in notebook (if running in Jupyter)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81467cf6",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics & Validation\n",
    "\n",
    "Final analysis and validation of the data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä PHASE 2 DATA PROCESSING - SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüî∑ 1. DATA LOADING\")\n",
    "print(f\"   ‚úÖ Total Orders Loaded: {len(df_orders):,}\")\n",
    "print(f\"   ‚úÖ Date Range: {df_orders['timestamp'].min()} to {df_orders['timestamp'].max()}\")\n",
    "print(f\"   ‚úÖ Total Stores: {len(stores_df)}\")\n",
    "\n",
    "print(\"\\nüî∑ 2. H3 HEXAGONAL AGGREGATION\")\n",
    "print(f\"   ‚úÖ H3 Resolution: {H3_RESOLUTION}\")\n",
    "print(f\"   ‚úÖ Hexagon Size: ~0.7 km¬≤ per hexagon\")\n",
    "print(f\"   ‚úÖ Total Hexagons Created: {len(gdf_demand):,}\")\n",
    "print(f\"   ‚úÖ Orders per Hexagon (avg): {gdf_demand['orders_count'].mean():.1f}\")\n",
    "print(f\"   ‚úÖ Orders per Hexagon (max): {gdf_demand['orders_count'].max()}\")\n",
    "\n",
    "print(\"\\nüî∑ 3. DEMAND METRICS\")\n",
    "print(f\"   ‚úÖ Demand Score Range: {gdf_demand['demand_score'].min():.2f} - {gdf_demand['demand_score'].max():.2f}\")\n",
    "print(f\"   ‚úÖ Avg Order Value: ‚Çπ{gdf_demand['avg_order_value'].mean():.0f}\")\n",
    "print(f\"   ‚úÖ Total Demand: ‚Çπ{gdf_demand['total_order_value'].sum():,.0f}\")\n",
    "print(f\"   ‚úÖ High Demand Hexagons (score > 7): {len(gdf_demand[gdf_demand['demand_score'] > 7])}\")\n",
    "\n",
    "print(\"\\nüî∑ 4. DISTANCE ANALYSIS\")\n",
    "print(f\"   ‚úÖ Distance Calculation Method: {'OSRM Road Network' if USE_OSRM else 'Euclidean (Haversine)'}\")\n",
    "print(f\"   ‚úÖ Min Distance to Store: {gdf_demand['dist_nearest_store_m'].min():.0f}m\")\n",
    "print(f\"   ‚úÖ Max Distance to Store: {gdf_demand['dist_nearest_store_m'].max():.0f}m\")\n",
    "print(f\"   ‚úÖ Avg Distance to Store: {gdf_demand['dist_nearest_store_m'].mean():.0f}m\")\n",
    "print(f\"   ‚úÖ Median Distance: {gdf_demand['dist_nearest_store_m'].median():.0f}m\")\n",
    "\n",
    "# Calculate coverage metrics\n",
    "within_3km = len(gdf_demand[gdf_demand['dist_nearest_store_m'] <= 3000])\n",
    "within_5km = len(gdf_demand[gdf_demand['dist_nearest_store_m'] <= 5000])\n",
    "within_10km = len(gdf_demand[gdf_demand['dist_nearest_store_m'] <= 10000])\n",
    "\n",
    "print(\"\\nüî∑ 5. COVERAGE ANALYSIS\")\n",
    "print(f\"   ‚úÖ Hexagons within 3km: {within_3km} ({within_3km/len(gdf_demand)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Hexagons within 5km: {within_5km} ({within_5km/len(gdf_demand)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Hexagons within 10km: {within_10km} ({within_10km/len(gdf_demand)*100:.1f}%)\")\n",
    "\n",
    "# Orders coverage\n",
    "orders_within_3km = gdf_demand[gdf_demand['dist_nearest_store_m'] <= 3000]['orders_count'].sum()\n",
    "orders_within_5km = gdf_demand[gdf_demand['dist_nearest_store_m'] <= 5000]['orders_count'].sum()\n",
    "total_orders = gdf_demand['orders_count'].sum()\n",
    "\n",
    "print(f\"   ‚úÖ Orders within 3km: {orders_within_3km:,} ({orders_within_3km/total_orders*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Orders within 5km: {orders_within_5km:,} ({orders_within_5km/total_orders*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüî∑ 6. DATABASE STORAGE\")\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text('SELECT COUNT(*) FROM demand_cells'))\n",
    "    db_count = result.fetchone()[0]\n",
    "    print(f\"   ‚úÖ Demand Cells in PostGIS: {db_count:,}\")\n",
    "    \n",
    "    # Check spatial index\n",
    "    idx_result = conn.execute(text(\"\"\"\n",
    "        SELECT indexname FROM pg_indexes \n",
    "        WHERE tablename = 'demand_cells' AND indexdef LIKE '%GIST%'\n",
    "    \"\"\"))\n",
    "    indexes = idx_result.fetchall()\n",
    "    print(f\"   ‚úÖ Spatial Indexes: {len(indexes)} GIST index(es)\")\n",
    "\n",
    "print(\"\\nüî∑ 7. OUTPUT FILES\")\n",
    "print(f\"   ‚úÖ Static Heatmaps: outputs/phase2_demand_analysis.png\")\n",
    "print(f\"   ‚úÖ Distribution Plots: outputs/phase2_statistical_distributions.png\")\n",
    "print(f\"   ‚úÖ Interactive Map: outputs/phase2_interactive_map.html\")\n",
    "\n",
    "print(\"\\nüî∑ 8. TOP 10 HIGH-DEMAND HEXAGONS\")\n",
    "top_hexagons = gdf_demand.nlargest(10, 'demand_score')[\n",
    "    ['h3_index', 'orders_count', 'demand_score', 'avg_order_value', 'dist_nearest_store_m']\n",
    "]\n",
    "print(top_hexagons.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ PHASE 2 DATA PROCESSING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìå Next Steps:\")\n",
    "print(\"   1. Review visualizations in the 'outputs/' directory\")\n",
    "print(\"   2. Open interactive map in browser for detailed exploration\")\n",
    "print(\"   3. Proceed to Phase 3: Candidate Site Generation\")\n",
    "print(\"   4. Run optimization algorithms to find optimal store locations\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
