{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1245fc3d",
   "metadata": {},
   "source": [
    "# üó∫Ô∏è Phase 2: Map Data & Processing Pipeline\n",
    "\n",
    "This notebook implements the complete geospatial data processing pipeline for SmartBlink:\n",
    "\n",
    "## Objectives:\n",
    "1. **Data Ingestion**: Load synthetic orders from PostgreSQL\n",
    "2. **GeoDataFrame Conversion**: Convert to GeoDataFrame with EPSG:4326\n",
    "3. **H3 Grid Aggregation**: Use hexagonal indexing (resolution 8)\n",
    "4. **Demand Analysis**: Calculate order counts, values, and temporal patterns\n",
    "5. **Distance Calculation**: Precompute distances to nearest stores using OSRM\n",
    "6. **Storage**: Update demand_cells table in PostGIS\n",
    "7. **Visualization**: Generate hex grid and demand heatmaps\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: SmartBlink Team  \n",
    "**Date**: November 2025  \n",
    "**Phase**: 2 - Data Processing Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000fc1c",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Required Libraries\n",
    "\n",
    "Install and import all necessary geospatial, data processing, and visualization libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d40c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.12' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely import wkt\n",
    "import h3\n",
    "\n",
    "# Database\n",
    "from prisma import Prisma\n",
    "import asyncio\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# HTTP requests for OSRM\n",
    "import requests\n",
    "import aiohttp\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"üì¶ H3 version: {h3.__version__}\")\n",
    "print(f\"üì¶ Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cfa0e",
   "metadata": {},
   "source": [
    "## 2. Configuration & Database Connection\n",
    "\n",
    "Set up database connection string and OSRM endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "DATABASE_URL = \"postgresql://smartblink:smartblink123@postgres:5432/smartblink\"\n",
    "\n",
    "# If running outside Docker, use localhost\n",
    "if not os.path.exists('/.dockerenv'):\n",
    "    DATABASE_URL = \"postgresql://smartblink:smartblink123@localhost:5432/smartblink\"\n",
    "\n",
    "# OSRM endpoint (optional - uncomment when OSRM is running)\n",
    "OSRM_URL = \"http://localhost:5000\"\n",
    "USE_OSRM = False  # Set to True when OSRM is available\n",
    "\n",
    "# H3 configuration\n",
    "H3_RESOLUTION = 8  # ~0.7km¬≤ hexagons\n",
    "\n",
    "# Analysis parameters\n",
    "ANALYSIS_DAYS = 90  # Look back 90 days\n",
    "\n",
    "print(f\"üìä Database: {DATABASE_URL.split('@')[-1]}\")\n",
    "print(f\"üó∫Ô∏è  H3 Resolution: {H3_RESOLUTION}\")\n",
    "print(f\"üîß OSRM Enabled: {USE_OSRM}\")\n",
    "print(f\"üìÖ Analysis Period: {ANALYSIS_DAYS} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce96241",
   "metadata": {},
   "source": [
    "## 3. Load Synthetic Orders from PostgreSQL\n",
    "\n",
    "Load order data from the database and inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect and load orders\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    ST_Y(location) as latitude,\n",
    "    ST_X(location) as longitude,\n",
    "    timestamp,\n",
    "    items_count,\n",
    "    order_value,\n",
    "    customer_id,\n",
    "    delivery_time_min,\n",
    "    status\n",
    "FROM orders\n",
    "ORDER BY timestamp DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üì• Loading orders from database...\")\n",
    "df_orders = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df_orders):,} orders\")\n",
    "print(f\"\\nüìä Data Shape: {df_orders.shape}\")\n",
    "print(f\"üìÖ Date Range: {df_orders['timestamp'].min()} to {df_orders['timestamp'].max()}\")\n",
    "print(f\"üí∞ Total Value: ‚Çπ{df_orders['order_value'].sum():,.2f}\")\n",
    "print(f\"\\nüîç Sample Data:\")\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e56b26",
   "metadata": {},
   "source": [
    "## 4. Convert to GeoDataFrame with EPSG:4326\n",
    "\n",
    "Transform pandas DataFrame into a GeoDataFrame with proper geometric projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Point geometries from lat/lon\n",
    "geometry = [Point(xy) for xy in zip(df_orders['longitude'], df_orders['latitude'])]\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_orders = gpd.GeoDataFrame(\n",
    "    df_orders,\n",
    "    geometry=geometry,\n",
    "    crs=\"EPSG:4326\"  # WGS84 - standard GPS coordinates\n",
    ")\n",
    "\n",
    "# Verify CRS\n",
    "print(f\"‚úÖ GeoDataFrame created\")\n",
    "print(f\"üìç CRS: {gdf_orders.crs}\")\n",
    "print(f\"üó∫Ô∏è  Geometry Type: {gdf_orders.geometry.geom_type.unique()[0]}\")\n",
    "print(f\"üìè Bounds: {gdf_orders.total_bounds}\")\n",
    "\n",
    "# Display sample\n",
    "gdf_orders[['latitude', 'longitude', 'order_value', 'timestamp', 'geometry']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bd580",
   "metadata": {},
   "source": [
    "## 5. H3 Hexagonal Grid Aggregation\n",
    "\n",
    "Apply H3 hexagonal indexing to create spatial bins for demand aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply H3 indexing to each order\n",
    "print(f\"üî∑ Applying H3 indexing at resolution {H3_RESOLUTION}...\")\n",
    "\n",
    "def lat_lon_to_h3(lat, lon, resolution=H3_RESOLUTION):\n",
    "    \"\"\"Convert lat/lon to H3 hexagon ID\"\"\"\n",
    "    try:\n",
    "        # H3 v4 API: h3.latlng_to_cell()\n",
    "        return h3.latlng_to_cell(lat, lon, resolution)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "gdf_orders['h3_index'] = gdf_orders.apply(\n",
    "    lambda row: lat_lon_to_h3(row['latitude'], row['longitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Remove any null H3 indices\n",
    "gdf_orders = gdf_orders[gdf_orders['h3_index'].notna()]\n",
    "\n",
    "# Get unique hexagons\n",
    "unique_hexes = gdf_orders['h3_index'].nunique()\n",
    "print(f\"‚úÖ Assigned {len(gdf_orders):,} orders to {unique_hexes:,} unique hexagons\")\n",
    "print(f\"üìä Average orders per hex: {len(gdf_orders) / unique_hexes:.1f}\")\n",
    "\n",
    "# Sample\n",
    "gdf_orders[['latitude', 'longitude', 'h3_index', 'order_value']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32470a",
   "metadata": {},
   "source": [
    "## 6. Aggregate Demand Metrics by Hexagon\n",
    "\n",
    "Calculate key metrics for each hexagon: order count, average value, and temporal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour from timestamp for temporal analysis\n",
    "gdf_orders['hour'] = gdf_orders['timestamp'].dt.hour\n",
    "\n",
    "# Aggregate by H3 hexagon\n",
    "demand_aggregation = gdf_orders.groupby('h3_index').agg({\n",
    "    'id': 'count',  # order_count\n",
    "    'order_value': ['sum', 'mean', 'std'],  # value metrics\n",
    "    'hour': lambda x: x.mode()[0] if len(x) > 0 else 12,  # peak_hour\n",
    "    'delivery_time_min': 'mean',  # avg delivery time\n",
    "    'latitude': 'first',  # for getting centroid (we'll recalculate properly)\n",
    "    'longitude': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "demand_aggregation.columns = [\n",
    "    'h3_index', 'orders_count', 'total_order_value', \n",
    "    'avg_order_value', 'std_order_value', 'peak_hour',\n",
    "    'avg_delivery_time', 'sample_lat', 'sample_lon'\n",
    "]\n",
    "\n",
    "# Calculate demand score (normalized 0-10)\n",
    "max_orders = demand_aggregation['orders_count'].max()\n",
    "demand_aggregation['demand_score'] = (\n",
    "    demand_aggregation['orders_count'] / max_orders * 10\n",
    ").round(2)\n",
    "\n",
    "print(f\"‚úÖ Aggregated {len(demand_aggregation):,} demand cells\")\n",
    "print(f\"\\nüìä Demand Statistics:\")\n",
    "print(demand_aggregation[['orders_count', 'avg_order_value', 'demand_score']].describe())\n",
    "\n",
    "demand_aggregation.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3dc2b",
   "metadata": {},
   "source": [
    "## 7. Calculate H3 Hexagon Centroids & Geometries\n",
    "\n",
    "Get the true geographic centroid for each hexagon and create polygon geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1979189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get H3 hexagon boundaries\n",
    "def h3_to_polygon(h3_index):\n",
    "    \"\"\"Convert H3 index to Shapely Polygon\"\"\"\n",
    "    # H3 v4 API: h3.cell_to_boundary()\n",
    "    boundary = h3.cell_to_boundary(h3_index, geo_json=True)\n",
    "    # H3 returns [lon, lat], but Shapely expects (lon, lat)\n",
    "    return Polygon(boundary)\n",
    "\n",
    "# Function to get H3 centroid\n",
    "def h3_to_centroid(h3_index):\n",
    "    \"\"\"Get centroid lat/lon from H3 index\"\"\"\n",
    "    # H3 v4 API: h3.cell_to_latlng()\n",
    "    lat, lon = h3.cell_to_latlng(h3_index)\n",
    "    return lat, lon\n",
    "\n",
    "print(\"üî∑ Computing hexagon centroids and geometries...\")\n",
    "\n",
    "# Calculate centroids\n",
    "demand_aggregation[['centroid_lat', 'centroid_lon']] = demand_aggregation['h3_index'].apply(\n",
    "    lambda x: pd.Series(h3_to_centroid(x))\n",
    ")\n",
    "\n",
    "# Create polygon geometries\n",
    "demand_aggregation['geometry'] = demand_aggregation['h3_index'].apply(h3_to_polygon)\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_demand = gpd.GeoDataFrame(\n",
    "    demand_aggregation,\n",
    "    geometry='geometry',\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created {len(gdf_demand):,} hexagon polygons\")\n",
    "print(f\"üìç Centroid example: ({gdf_demand.iloc[0]['centroid_lat']:.4f}, {gdf_demand.iloc[0]['centroid_lon']:.4f})\")\n",
    "\n",
    "gdf_demand[['h3_index', 'orders_count', 'demand_score', 'centroid_lat', 'centroid_lon']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f89073",
   "metadata": {},
   "source": [
    "## 8. Calculate Distance to Nearest Store\n",
    "\n",
    "For each hexagon, we'll calculate:\n",
    "- **Road network distance** using OSRM (if available)\n",
    "- **Fallback to Euclidean distance** if OSRM is unavailable\n",
    "- **Travel time** to nearest store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# Load stores from database\n",
    "print(\"üìç Loading stores from database...\")\n",
    "stores_query = \"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        name,\n",
    "        ST_Y(location::geometry) as lat,\n",
    "        ST_X(location::geometry) as lon\n",
    "    FROM \"Store\"\n",
    "    ORDER BY id;\n",
    "\"\"\"\n",
    "\n",
    "stores_df = pd.read_sql(stores_query, engine)\n",
    "print(f\"‚úÖ Loaded {len(stores_df)} stores\")\n",
    "print(stores_df[['id', 'name', 'lat', 'lon']])\n",
    "\n",
    "# Function to calculate Euclidean distance as fallback\n",
    "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance in meters using Haversine formula\"\"\"\n",
    "    from math import radians, sin, cos, sqrt, atan2\n",
    "    \n",
    "    R = 6371000  # Earth radius in meters\n",
    "    \n",
    "    lat1_rad, lon1_rad = radians(lat1), radians(lon1)\n",
    "    lat2_rad, lon2_rad = radians(lat2), radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "# Function to query OSRM for distances\n",
    "async def get_osrm_distances_batch(centroids: List[Tuple[float, float]], \n",
    "                                     stores: List[Tuple[float, float]]) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Query OSRM table service to get distance matrix\n",
    "    Returns: distances array [centroids x stores] in meters, or None if OSRM unavailable\n",
    "    \"\"\"\n",
    "    if not USE_OSRM:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Format coordinates as lon,lat for OSRM\n",
    "        centroid_coords = \";\".join([f\"{lon},{lat}\" for lat, lon in centroids])\n",
    "        store_coords = \";\".join([f\"{lon},{lat}\" for lat, lon in stores])\n",
    "        all_coords = f\"{centroid_coords};{store_coords}\"\n",
    "        \n",
    "        # OSRM table service\n",
    "        url = f\"{OSRM_URL}/table/v1/driving/{all_coords}\"\n",
    "        params = {\n",
    "            \"sources\": \";\".join([str(i) for i in range(len(centroids))]),\n",
    "            \"destinations\": \";\".join([str(i) for i in range(len(centroids), len(centroids) + len(stores))])\n",
    "        }\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params, timeout=30) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    distances = np.array(data['distances'])\n",
    "                    return distances\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è OSRM returned status {response.status}\")\n",
    "                    return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è OSRM not available: {e}\")\n",
    "        return None\n",
    "\n",
    "# Calculate distances\n",
    "print(\"\\nüöó Calculating distances to nearest store...\")\n",
    "\n",
    "# Prepare store coordinates\n",
    "store_coords = list(zip(stores_df['lat'], stores_df['lon']))\n",
    "\n",
    "# Initialize distance columns\n",
    "gdf_demand['dist_nearest_store_m'] = 0.0\n",
    "gdf_demand['travel_time_nearest_store_sec'] = 0.0\n",
    "gdf_demand['nearest_store_id'] = None\n",
    "\n",
    "# Try OSRM first (batch processing)\n",
    "if USE_OSRM:\n",
    "    print(\"Attempting OSRM distance calculation...\")\n",
    "    centroid_coords = list(zip(gdf_demand['centroid_lat'], gdf_demand['centroid_lon']))\n",
    "    \n",
    "    # Process in batches of 100 to avoid timeout\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(centroid_coords), batch_size):\n",
    "        batch = centroid_coords[i:i+batch_size]\n",
    "        distances = asyncio.run(get_osrm_distances_batch(batch, store_coords))\n",
    "        \n",
    "        if distances is not None:\n",
    "            # Find minimum distance and corresponding store for each hexagon\n",
    "            min_indices = np.argmin(distances, axis=1)\n",
    "            min_distances = distances[np.arange(len(batch)), min_indices]\n",
    "            \n",
    "            gdf_demand.loc[i:i+len(batch)-1, 'dist_nearest_store_m'] = min_distances\n",
    "            gdf_demand.loc[i:i+len(batch)-1, 'nearest_store_id'] = stores_df.iloc[min_indices]['id'].values\n",
    "            \n",
    "            # Estimate travel time (assuming 25 km/h average speed in city)\n",
    "            gdf_demand.loc[i:i+len(batch)-1, 'travel_time_nearest_store_sec'] = min_distances / (25000/3600)\n",
    "        else:\n",
    "            USE_OSRM = False\n",
    "            break\n",
    "        \n",
    "        if (i + batch_size) % 500 == 0:\n",
    "            print(f\"  Processed {min(i + batch_size, len(centroid_coords)):,}/{len(centroid_coords):,} hexagons\")\n",
    "\n",
    "# Fallback to Euclidean distance\n",
    "if not USE_OSRM or gdf_demand['dist_nearest_store_m'].sum() == 0:\n",
    "    print(\"üìê Using Euclidean distance (OSRM not available)...\")\n",
    "    \n",
    "    for idx, row in gdf_demand.iterrows():\n",
    "        hex_lat, hex_lon = row['centroid_lat'], row['centroid_lon']\n",
    "        \n",
    "        # Calculate distance to each store\n",
    "        distances = [\n",
    "            euclidean_distance(hex_lat, hex_lon, store_lat, store_lon)\n",
    "            for store_lat, store_lon in store_coords\n",
    "        ]\n",
    "        \n",
    "        # Find nearest store\n",
    "        min_idx = np.argmin(distances)\n",
    "        min_dist = distances[min_idx]\n",
    "        \n",
    "        gdf_demand.at[idx, 'dist_nearest_store_m'] = min_dist\n",
    "        gdf_demand.at[idx, 'nearest_store_id'] = stores_df.iloc[min_idx]['id']\n",
    "        \n",
    "        # Estimate travel time (assuming 25 km/h + 20% detour factor for road network)\n",
    "        gdf_demand.at[idx, 'travel_time_nearest_store_sec'] = (min_dist * 1.2) / (25000/3600)\n",
    "\n",
    "print(\"\\n‚úÖ Distance calculation complete!\")\n",
    "print(f\"üìä Distance stats:\")\n",
    "print(f\"  - Min: {gdf_demand['dist_nearest_store_m'].min():.0f}m\")\n",
    "print(f\"  - Max: {gdf_demand['dist_nearest_store_m'].max():.0f}m\")\n",
    "print(f\"  - Mean: {gdf_demand['dist_nearest_store_m'].mean():.0f}m\")\n",
    "print(f\"  - Median: {gdf_demand['dist_nearest_store_m'].median():.0f}m\")\n",
    "\n",
    "gdf_demand[['h3_index', 'orders_count', 'demand_score', 'dist_nearest_store_m', 'travel_time_nearest_store_sec']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202a940",
   "metadata": {},
   "source": [
    "## 9. Store Results in PostGIS Database\n",
    "\n",
    "Update the `demand_cells` table with calculated metrics and geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "print(\"üíæ Storing demand cell data in PostGIS...\")\n",
    "\n",
    "# Drop existing demand cells to replace with H3-based cells\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text('DELETE FROM \"DemandCell\"'))\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Cleared existing demand cells\")\n",
    "\n",
    "# Prepare data for insertion\n",
    "insert_count = 0\n",
    "errors = []\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    for idx, row in gdf_demand.iterrows():\n",
    "        try:\n",
    "            # Convert polygon to WKT\n",
    "            polygon_wkt = row['geometry'].wkt\n",
    "            \n",
    "            insert_query = text(\"\"\"\n",
    "                INSERT INTO \"DemandCell\" (\n",
    "                    h3_index,\n",
    "                    geometry,\n",
    "                    order_count,\n",
    "                    total_demand,\n",
    "                    avg_order_value,\n",
    "                    demand_score,\n",
    "                    distance_to_nearest_store\n",
    "                ) VALUES (\n",
    "                    :h3_index,\n",
    "                    ST_SetSRID(ST_GeomFromText(:geometry), 4326),\n",
    "                    :order_count,\n",
    "                    :total_demand,\n",
    "                    :avg_order_value,\n",
    "                    :demand_score,\n",
    "                    :distance\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(insert_query, {\n",
    "                'h3_index': row['h3_index'],\n",
    "                'geometry': polygon_wkt,\n",
    "                'order_count': int(row['orders_count']),\n",
    "                'total_demand': float(row['total_order_value']),\n",
    "                'avg_order_value': float(row['avg_order_value']),\n",
    "                'demand_score': float(row['demand_score']),\n",
    "                'distance': float(row['dist_nearest_store_m'])\n",
    "            })\n",
    "            \n",
    "            insert_count += 1\n",
    "            \n",
    "            if insert_count % 100 == 0:\n",
    "                conn.commit()\n",
    "                print(f\"  Inserted {insert_count}/{len(gdf_demand)} cells...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors.append(f\"Row {idx}: {str(e)}\")\n",
    "            if len(errors) <= 5:\n",
    "                print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully inserted {insert_count} demand cells into PostGIS\")\n",
    "if errors:\n",
    "    print(f\"‚ö†Ô∏è {len(errors)} errors occurred\")\n",
    "\n",
    "# Verify insertion\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text('SELECT COUNT(*) as count FROM \"DemandCell\"'))\n",
    "    count = result.fetchone()[0]\n",
    "    print(f\"\\nüìä Database verification: {count} demand cells in PostGIS\")\n",
    "    \n",
    "    # Sample query with spatial data\n",
    "    sample = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            h3_index,\n",
    "            order_count,\n",
    "            demand_score,\n",
    "            ROUND(distance_to_nearest_store::numeric, 0) as dist_m,\n",
    "            ST_AsText(ST_Centroid(geometry)) as centroid\n",
    "        FROM \"DemandCell\"\n",
    "        ORDER BY demand_score DESC\n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(\"\\nüî• Top 5 demand cells:\")\n",
    "    for row in sample:\n",
    "        print(f\"  H3: {row[0][:10]}... | Orders: {row[1]:3d} | Score: {row[2]:.1f} | Dist: {row[3]}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e40956",
   "metadata": {},
   "source": [
    "## 10. Visualizations\n",
    "\n",
    "Create comprehensive visualizations to analyze demand patterns and validate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "\n",
    "print(\"üìä Creating visualizations...\")\n",
    "\n",
    "# 1. Demand Heatmap (Matplotlib)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# A. Hexagon Grid with Demand Score\n",
    "ax1 = axes[0, 0]\n",
    "gdf_demand.plot(\n",
    "    column='demand_score',\n",
    "    cmap='YlOrRd',\n",
    "    legend=True,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.7,\n",
    "    ax=ax1\n",
    ")\n",
    "# Plot stores\n",
    "stores_gdf = gpd.GeoDataFrame(\n",
    "    stores_df,\n",
    "    geometry=gpd.points_from_xy(stores_df['lon'], stores_df['lat']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "stores_gdf.plot(ax=ax1, color='blue', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax1.set_title('H3 Hexagon Grid - Demand Score Heatmap', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.legend()\n",
    "\n",
    "# B. Order Count Heatmap\n",
    "ax2 = axes[0, 1]\n",
    "gdf_demand.plot(\n",
    "    column='orders_count',\n",
    "    cmap='plasma',\n",
    "    legend=True,\n",
    "    edgecolor='gray',\n",
    "    linewidth=0.2,\n",
    "    alpha=0.8,\n",
    "    ax=ax2\n",
    ")\n",
    "stores_gdf.plot(ax=ax2, color='cyan', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax2.set_title('Order Count per Hexagon', fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel('Longitude')\n",
    "ax2.set_ylabel('Latitude')\n",
    "ax2.legend()\n",
    "\n",
    "# C. Average Order Value\n",
    "ax3 = axes[1, 0]\n",
    "gdf_demand.plot(\n",
    "    column='avg_order_value',\n",
    "    cmap='viridis',\n",
    "    legend=True,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.7,\n",
    "    ax=ax3\n",
    ")\n",
    "stores_gdf.plot(ax=ax3, color='red', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax3.set_title('Average Order Value (‚Çπ)', fontsize=16, fontweight='bold')\n",
    "ax3.set_xlabel('Longitude')\n",
    "ax3.set_ylabel('Latitude')\n",
    "ax3.legend()\n",
    "\n",
    "# D. Distance to Nearest Store\n",
    "ax4 = axes[1, 1]\n",
    "gdf_demand.plot(\n",
    "    column='dist_nearest_store_m',\n",
    "    cmap='coolwarm_r',\n",
    "    legend=True,\n",
    "    edgecolor='gray',\n",
    "    linewidth=0.2,\n",
    "    alpha=0.8,\n",
    "    ax=ax4\n",
    ")\n",
    "stores_gdf.plot(ax=ax4, color='green', marker='*', markersize=300, label='Stores', zorder=5)\n",
    "ax4.set_title('Distance to Nearest Store (meters)', fontsize=16, fontweight='bold')\n",
    "ax4.set_xlabel('Longitude')\n",
    "ax4.set_ylabel('Latitude')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/phase2_demand_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: outputs/phase2_demand_analysis.png\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Statistical Distribution Plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Distribution of demand scores\n",
    "axes[0, 0].hist(gdf_demand['demand_score'], bins=30, color='orange', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Demand Scores', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Demand Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(gdf_demand['demand_score'].mean(), color='red', linestyle='--', label=f'Mean: {gdf_demand[\"demand_score\"].mean():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Distribution of order counts\n",
    "axes[0, 1].hist(gdf_demand['orders_count'], bins=30, color='purple', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of Order Counts', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Orders per Hexagon')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(gdf_demand['orders_count'].mean(), color='red', linestyle='--', label=f'Mean: {gdf_demand[\"orders_count\"].mean():.1f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Distribution of distances\n",
    "axes[1, 0].hist(gdf_demand['dist_nearest_store_m'], bins=30, color='teal', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('Distribution of Distances to Nearest Store', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Distance (meters)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(gdf_demand['dist_nearest_store_m'].mean(), color='red', linestyle='--', label=f'Mean: {gdf_demand[\"dist_nearest_store_m\"].mean():.0f}m')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Scatter: Demand Score vs Distance\n",
    "axes[1, 1].scatter(gdf_demand['dist_nearest_store_m'], gdf_demand['demand_score'], \n",
    "                   alpha=0.6, c=gdf_demand['orders_count'], cmap='viridis', s=50)\n",
    "axes[1, 1].set_title('Demand Score vs Distance to Store', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Distance to Nearest Store (m)')\n",
    "axes[1, 1].set_ylabel('Demand Score')\n",
    "cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "cbar.set_label('Order Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/phase2_statistical_distributions.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: outputs/phase2_statistical_distributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Interactive Folium Map\n",
    "import folium\n",
    "from folium import plugins\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "print(\"üó∫Ô∏è Creating interactive Folium map...\")\n",
    "\n",
    "# Create base map centered on Delhi NCR\n",
    "center_lat = gdf_demand['centroid_lat'].mean()\n",
    "center_lon = gdf_demand['centroid_lon'].mean()\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=11,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Create colormap for demand score\n",
    "colormap = LinearColormap(\n",
    "    colors=['yellow', 'orange', 'red', 'darkred'],\n",
    "    vmin=gdf_demand['demand_score'].min(),\n",
    "    vmax=gdf_demand['demand_score'].max(),\n",
    "    caption='Demand Score'\n",
    ")\n",
    "\n",
    "# Add hexagon polygons\n",
    "for idx, row in gdf_demand.iterrows():\n",
    "    # Get polygon coordinates\n",
    "    coords = list(row['geometry'].exterior.coords)\n",
    "    coords_folium = [[lat, lon] for lon, lat in coords]\n",
    "    \n",
    "    # Color based on demand score\n",
    "    color = colormap(row['demand_score'])\n",
    "    \n",
    "    # Create popup\n",
    "    popup_html = f\"\"\"\n",
    "    <b>H3 Index:</b> {row['h3_index']}<br>\n",
    "    <b>Orders:</b> {row['orders_count']}<br>\n",
    "    <b>Demand Score:</b> {row['demand_score']:.2f}<br>\n",
    "    <b>Avg Order Value:</b> ‚Çπ{row['avg_order_value']:.0f}<br>\n",
    "    <b>Distance to Store:</b> {row['dist_nearest_store_m']:.0f}m<br>\n",
    "    <b>Peak Hour:</b> {row['peak_hour']:.0f}:00\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.Polygon(\n",
    "        locations=coords_folium,\n",
    "        color='black',\n",
    "        weight=1,\n",
    "        fill=True,\n",
    "        fillColor=color,\n",
    "        fillOpacity=0.6,\n",
    "        popup=folium.Popup(popup_html, max_width=300)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add store markers\n",
    "for idx, store in stores_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[store['lat'], store['lon']],\n",
    "        popup=f\"<b>{store['name']}</b><br>Store ID: {store['id']}\",\n",
    "        icon=folium.Icon(color='blue', icon='shopping-cart', prefix='fa'),\n",
    "        tooltip=store['name']\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add colormap legend\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save map\n",
    "m.save('../outputs/phase2_interactive_map.html')\n",
    "print(\"‚úÖ Saved: outputs/phase2_interactive_map.html\")\n",
    "print(\"   Open this file in a browser to explore the interactive map!\")\n",
    "\n",
    "# Display in notebook (if running in Jupyter)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81467cf6",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics & Validation\n",
    "\n",
    "Final analysis and validation of the data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä PHASE 2 DATA PROCESSING - SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüî∑ 1. DATA LOADING\")\n",
    "print(f\"   ‚úÖ Total Orders Loaded: {len(orders_df):,}\")\n",
    "print(f\"   ‚úÖ Date Range: {orders_df['created_at'].min()} to {orders_df['created_at'].max()}\")\n",
    "print(f\"   ‚úÖ Total Stores: {len(stores_df)}\")\n",
    "\n",
    "print(\"\\nüî∑ 2. H3 HEXAGONAL AGGREGATION\")\n",
    "print(f\"   ‚úÖ H3 Resolution: {H3_RESOLUTION}\")\n",
    "print(f\"   ‚úÖ Hexagon Size: ~0.7 km¬≤ per hexagon\")\n",
    "print(f\"   ‚úÖ Total Hexagons Created: {len(gdf_demand):,}\")\n",
    "print(f\"   ‚úÖ Orders per Hexagon (avg): {gdf_demand['orders_count'].mean():.1f}\")\n",
    "print(f\"   ‚úÖ Orders per Hexagon (max): {gdf_demand['orders_count'].max()}\")\n",
    "\n",
    "print(\"\\nüî∑ 3. DEMAND METRICS\")\n",
    "print(f\"   ‚úÖ Demand Score Range: {gdf_demand['demand_score'].min():.2f} - {gdf_demand['demand_score'].max():.2f}\")\n",
    "print(f\"   ‚úÖ Avg Order Value: ‚Çπ{gdf_demand['avg_order_value'].mean():.0f}\")\n",
    "print(f\"   ‚úÖ Total Demand: ‚Çπ{gdf_demand['total_order_value'].sum():,.0f}\")\n",
    "print(f\"   ‚úÖ High Demand Hexagons (score > 7): {len(gdf_demand[gdf_demand['demand_score'] > 7])}\")\n",
    "\n",
    "print(\"\\nüî∑ 4. DISTANCE ANALYSIS\")\n",
    "print(f\"   ‚úÖ Distance Calculation Method: {'OSRM Road Network' if USE_OSRM else 'Euclidean (Haversine)'}\")\n",
    "print(f\"   ‚úÖ Min Distance to Store: {gdf_demand['dist_nearest_store_m'].min():.0f}m\")\n",
    "print(f\"   ‚úÖ Max Distance to Store: {gdf_demand['dist_nearest_store_m'].max():.0f}m\")\n",
    "print(f\"   ‚úÖ Avg Distance to Store: {gdf_demand['dist_nearest_store_m'].mean():.0f}m\")\n",
    "print(f\"   ‚úÖ Median Distance: {gdf_demand['dist_nearest_store_m'].median():.0f}m\")\n",
    "\n",
    "# Calculate coverage metrics\n",
    "within_3km = len(gdf_demand[gdf_demand['dist_nearest_store_m'] <= 3000])\n",
    "within_5km = len(gdf_demand[gdf_demand['dist_nearest_store_m'] <= 5000])\n",
    "within_10km = len(gdf_demand[gdf_demand['dist_nearest_store_m'] <= 10000])\n",
    "\n",
    "print(\"\\nüî∑ 5. COVERAGE ANALYSIS\")\n",
    "print(f\"   ‚úÖ Hexagons within 3km: {within_3km} ({within_3km/len(gdf_demand)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Hexagons within 5km: {within_5km} ({within_5km/len(gdf_demand)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Hexagons within 10km: {within_10km} ({within_10km/len(gdf_demand)*100:.1f}%)\")\n",
    "\n",
    "# Orders coverage\n",
    "orders_within_3km = gdf_demand[gdf_demand['dist_nearest_store_m'] <= 3000]['orders_count'].sum()\n",
    "orders_within_5km = gdf_demand[gdf_demand['dist_nearest_store_m'] <= 5000]['orders_count'].sum()\n",
    "total_orders = gdf_demand['orders_count'].sum()\n",
    "\n",
    "print(f\"   ‚úÖ Orders within 3km: {orders_within_3km:,} ({orders_within_3km/total_orders*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Orders within 5km: {orders_within_5km:,} ({orders_within_5km/total_orders*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüî∑ 6. DATABASE STORAGE\")\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text('SELECT COUNT(*) FROM \"DemandCell\"'))\n",
    "    db_count = result.fetchone()[0]\n",
    "    print(f\"   ‚úÖ Demand Cells in PostGIS: {db_count:,}\")\n",
    "    \n",
    "    # Check spatial index\n",
    "    idx_result = conn.execute(text(\"\"\"\n",
    "        SELECT indexname FROM pg_indexes \n",
    "        WHERE tablename = 'DemandCell' AND indexdef LIKE '%GIST%'\n",
    "    \"\"\"))\n",
    "    indexes = idx_result.fetchall()\n",
    "    print(f\"   ‚úÖ Spatial Indexes: {len(indexes)} GIST index(es)\")\n",
    "\n",
    "print(\"\\nüî∑ 7. OUTPUT FILES\")\n",
    "print(f\"   ‚úÖ Static Heatmaps: outputs/phase2_demand_analysis.png\")\n",
    "print(f\"   ‚úÖ Distribution Plots: outputs/phase2_statistical_distributions.png\")\n",
    "print(f\"   ‚úÖ Interactive Map: outputs/phase2_interactive_map.html\")\n",
    "\n",
    "print(\"\\nüî∑ 8. TOP 10 HIGH-DEMAND HEXAGONS\")\n",
    "top_hexagons = gdf_demand.nlargest(10, 'demand_score')[\n",
    "    ['h3_index', 'orders_count', 'demand_score', 'avg_order_value', 'dist_nearest_store_m']\n",
    "]\n",
    "print(top_hexagons.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ PHASE 2 DATA PROCESSING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìå Next Steps:\")\n",
    "print(\"   1. Review visualizations in the 'outputs/' directory\")\n",
    "print(\"   2. Open interactive map in browser for detailed exploration\")\n",
    "print(\"   3. Proceed to Phase 3: Candidate Site Generation\")\n",
    "print(\"   4. Run optimization algorithms to find optimal store locations\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
